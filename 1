Some Core Ideas in Computing
algorithm is a procedure consisting of finite set of steps, possibly including loops & conditionals, that solves a given problem.
turing machine is a formal description of the problem an algorithm solves
problem is a relation between input and output 
relation is a set of pairs i.e. which outputs are acceptable for which inputs

Asymptotic notation:

O - Big Oh (Omicron)
^ - Omega
8 - Theta

O(g) is a set of functions that do not grow faster than g. A function f is in O(g) if it satified the following conditions:
f(n) <= c.g(n)
^(g) is a set of functions that are not slower than g.
f(n) >= c.g(n)
8(n) is a intersection of O(n) n ^(n) i.e a function that satifies the following conditions:
c1.g(n) <= f(n) <= c2.g(n)

In a nutshell we can summarize these concepts into:

O(g(n)) denotes the set of all f(n) such that there exists positive constants
C and n0 with |f(n) <= Cg(n) for all n >= n0.
- This can also be refered to as "order at most g(n)".
^(g(n)) denotes the set of all f(n) such that there exist positive constants
C and n0 with f(n) >= Cg(n) for all n >= n0.
- This can also be refered to as "order at least g(n)".
8(f(n)) denotes the set of all f(n) such that there exist positive constants
n0, C, C1 ith Cg(n) < f(n) < Cg(n) for all n >= n0.
- This can also be refered to as "order exactly g(n)".

We want to refer these notations used in formulas as set of functions rather than
single functions:
So functions A, B are set of functions.
A + B denotes the set {a+b | a e A and b e B } and "1 + O(n^-1)" can be taken to mean the set of all functions
of the form 1 + f(n), where |f(n)| <= Cn^-1  for some C and all large n.
The phenomenon called one-way equality arises, as:
1 + O(n^-1) = O(1) and not the other way round

Empirical Analysis of algorithms:
1. if possible do not worry about it
2. for timing use timeit
python -m timeit -s'import myModule as m' 'm.myFunction()'
import timeit

timeit.timeit("x = sum(range(10))")

3. to find bottlenecks use a profiler
import cProfiler

cProfiler.run("main()")
use trace module for terse information
python call graph to visualize calls

4. plot your results.
5. judiciously draw conclusions based on timing comparisons
6. judiciously draw out conclusions based on asymptotic notation
references:
how not to lie with statistics: correct way to sumarize benchmark results.
Bast & Weber's don't compare averages.
Citron's harmonic or geometric mean, does it really matter?

Graphs: G=(V,E) consists of a set of nodes V, and edges between them, E. If the edges have a direction, we say the graph is directed.
Nodes with an edge between then are adjacent. The edge is incident to both.
The nodes that are adjacent to v are neighbours of v.
Degree of a node is the number of edges incident to it.
Subgraph of G=(V,E) is a subset of V and a subset of E.
A path is a subgraph where the edges connect nodes in a sequence without revisiting nodes.
A cycle is like a path except the last node links the first.
A weighted graph has weight to its edges.
The length of a path or cycle is the sum of its edge weights & for unweighted graphs the number of edges.
A forest is a cycle free graph and a connected forest is a tree.
A forest consists of one or more trees.

references:
graph-tool: https://graph-tool.skewed.de/static/doc/quickstart.html#creating-and-manipulating-graphs
python patterns - Implementing graphs
https://www.python.org/doc/essays/graphs
sage module for accounting  & statistical computations
tournaments:
i). round-robin/ handshake problem
- the soln: n-1+n-2..+0 = sum(i for i in range(n))
n-1
[i = n(n-1)/2
i=0

 							49
caveat: sum of 100 numbers with 50 pairings gives us 101[i
							i=0

ii). hare & the tortoise/ knockout system
h-1
[2^i = n-1
i=0
	n=2^h gives hare
	h=log n gives tortoise

permutations as orderings of n objects. n!
n . (n-1) . (n-2) . .. . 1

caveat: 2^a+b is 2^a * 2^b

binomial co-efficient/combinations as a combinations of k elements drawn from set n

C(n,k)

popular algo sol:

0). T(n)=T(n-1)+1 - processing sequence 0(n)
1). T(n)=T(n-1)+n - handshake problem 0(n^2)
2). T(n)=2T(n-1)+1 - towers of hanoi 0(2n)
3). T(n)=2T(n-1)+n  
4). T(n)=T(n/2)+1 - binary search 0(lg n)
5). T(n)=T(n/2)+n - randomized select 0(n)
6). T(n)=2T(n/2)+1 - tree traversal 0(n)
7). T(n)=2T(n/2)+n - sorting by divide & conquer 0(nlg n)

3).
	use n = 2T(n-1) + n
	2{2(n-1-1) + n-1} + n
	2{2{2(n-1-1-1) + n-1-1} +  n-1} + n
	2{2{2(n-3) + n-2} + n-1} + n
	= 2 . n + n
	= 2n
	= 0(2n)
4. 
	use n = n/2 + 1
	(n/2 + 1)
	{(n/4 + 1) + 1}
	{{(n/8 + 1) + 1} + 1}
using i = lg n as base case
									lg n-1
T(1) = T(n/2^i) + [1
									0
		 = 1	+ i
		 = 0(lg n) 

5.
	use n = n/2 + n
	(n/2 + n)
	{(n/4 + n/2) + n}
	{{(n/8 + n/4) + n/2} + n}
	{{{(n/16 + n/8) + n/4} + n/2} + n}
using i = lg n as base case
									lg n-1
T(1) = T(n/2^i) + [n/2
									0
			= T(1) + [(n/2^i)
			= 1 + n
			= 0(n)

6.
	use n as 2T(n/2) + 1
	2(n/2) + 1
	2{2(n/4) + 1} + 1
	2{2{2(n/8) + 1} + 1 + 1
	8(n/8) + 3
	n + lg n
	= 0(n)

7.
	// Needs more proof especially the root
	use n as 2T(n/2) + n
	2(n/2) + n
	2{2(n/4) + n/2} + n
	2{2{2(n/8) + n/4} + n/2} + n
	8{(n/8) + n.i/2^i + n
	n + n.lg n
	= 0(n lg n)

	1.1 Consider the statement `As machines get faster and memory cheaper, algorithms become less important`. Is this true or false? And Why?
			ans:False. As machines get faster and use more memory, poor algorithms will lead to disaster in performance.
	1.2 Find a way of checking whether two strings are anagrams of each other: `debit card & bad credit`?
			ans: By sorting the characters in the strings and counting each character's frequency using Collections.Counter would scale even better.
	
	2.1 Why would it be problematic to construct a multi-dimensional array with the expression [[0]*10]*10?
	-	It would be equivalent to using the same list 10 times.
	- anecdotal test:
	a = [[0]*10]*10
	a[0][0]=23

	2.2 Assuming abit unrealistically that allocating a block of memory takes constant time provided you leave it uninitialized.
	You want an array of n integers, and you want to keep track of whether each entry is uninitialized or whether it contains a number you put there.
	This is a check you want to be able to do at constant time for any entry. How would you do this with only constant time for initialization?
	And how could you use this to initialize an empty adjacency array in constant time, thereby avoiding an otherwise obligatory quadratic min running time?
	-	A, B, C = size n
	- count of entries
	A[i] = x
	B[i] = count
	C[count] = i

	2.3 Show that 0 and  @ are inverses of each other;i.e. if f is 0(g), then g is @(f) & vice-versa?
	- f(n) >= cg(n) >= f(n)
	- g(n) are satisfied using constant 1/c

	2.4 Log can have different bases but this is not a big deal.
	To see why, consider the equation: log (b,n) = log(a,n)/log(a,b)
	set log(a,n)/log(a,b) as m
	b^m = n
	m log b = log n
	this neutralizes to a common base and m to a contant

	how about:
	log (b, n) = log (a, n) / log (a, b)
	log(a, b).log(b, n) = log(a, n)
	reduce from log
	b^(log(b, n)) = n - using a as standard base
	thus (log(b, n)) is a constant, c
	b^c = n
	c.log b = log n - base is constant now

	2.5 Show that any increasing exponential (0(k^n) for k>1)
	asymptotically dominates any polynomial (0(n^j) for j>0)
	-	k^n >= cn^j
	- set c = 1
	- k^n > n^j
	- n log(k,k) > j * log(k,n)
	- n > jlog(k,n)	-	Increasing linear functions dominate logarithmic.

	2.6 Show that any polynomial asymptotically dominates any 0(log(n)).
	- n^j > log n
	- j log n > log (log n)
	- set log n as m
	- jm > log m

	2.7 Asymptotic complexities of various operations on Python lists, such as;
	indexing, item assign, reversing, appending & inserting?
	How would these be in a linked list?
	- accessing a linked list involves traversing the list or atleast halfway giving linear running time
	- Swapping elements around is constant time
	- Modifying (inserting or deleting) is done in constant time for linked list.
	What about example list.extend?
	- Anything that involves finding or modifying a certain position basically takes constant time because the underlying implementation is arrays.
	- Swapping elements around is constant time
	- Modifying the list structure (by inserting or deleting element, except at the end) is generally linear
	2.8 Show that 0(f) + 0(g) = 0(f+g) ? Also try your hand with max(0(f), 0(g))=0(max(f,g)) = 0(f+g)
	- if function F(n) <= c.f(n)
	- G(n) <= c.g(n)
	- G(n) + F(n) <= c.g(n) + c.f(n)
	- c.(G(n) + F(n))
	- max(0(f),0(g)) = 0(max(f,g))
	- max(f,g) = 0(f+g)						# maximum value grows as fast as the sum

	2.9 Let T be an arbitrary rooted tree with atleast 3 nodes, where each node has exactly 2 children.
	If T has n leaves, how many nodes does it have?
	- number of leaves is n
	- number of node children is 2m
	- number of internal nodes(parent) is m
	= 2m = m + n-1			# internal nodes + except root
	= 0(n) = m + n-1
	= m <= n-1

	2.10 Show that acyclic DAG can have any underlying structure whatsoever. Any undirected graph can be the underlying graph for DAG,
	or, given a graph, you can always orient its edges so that the resulting digraph is a DAG
	- Numbering the edges. Orient the ordering from lower to higher numbers.

	2.12 Consider a graph representation. You use a dict and let each key be a pair(tuple) of two nodes, with corresponding value set to the edge weight.
	W[u, v] = 24. What are pros & cons of this approach? How would you mitigate the cons?
	pros: 
		- Useful in finding edge weights
		- You dont need to access all neighbours of a node
	cons:
		- Less efficient in looking up node neighbours
		- Handling membership, finding the degree of a node is handled differently, potentially increasing complexity
	improvements:
		- Using an extra data structure such as global list of nodes or simple adjacency lists

	3.1 Show that the properties described in the section `Working with sums` are correct ?
	- c.f(n) + c.g(n)
	- c [ 0(f(n) + 0(g))
	- c [ 0(f(n) + g(n))

	3.2 Use rules of the road to show that n(n - 1)/2 is 0(n^2)
from collections import dict
from collections import dict
	- n^2/2 - n/2
	- n^2.k - n.k			# k constant factor
	- k(n^2 - n)
	- n^2 dominates the equation
	
	3.3 The sum of the first k non-negative integer powers of 2 is 2^k+1 - 1. Show how this property lets you represent any positive integer as binary number?
	- why binary works is because any sum of 2 to power k is equivalent to n-1 (i.e. n is next power of 2).
			k
	- [ 2^i = n - 1			# k+1 in this case is the tortoise i.e. height of soln
			k=0
	- n = 2^k+1 - 1
	- n = 2^(k+1)+1 - 1			# k = k + 1
	- n + (2^(k+1)) = 2^(k+1)+1 - 1
	- n + 2^(2) = 2^3 - 1		# using k = 1
	- n + 4 = 7
	- n = 3									# as powers of 2
	- n = 7									# as powers of 2

	3.4 In `hare & tortoise`, two methods of looking for a number are sketched. Turn these methods into number guessing algorithms & represent them as python programs?
	-	h = lg n
		T(n) = lg n
		= lg (lg n)
		having lg n as m
		= lg m
	- 2^h = n

	3.5 Show that C(n,k) = C(n,n-k) ?
	- C(n, k) = n!/k!(n-k)!
	- C(n, n-k) = n!/(n-k)!(n-(n-k))!
	- C(n, n-k) = n!/(n-k)!k!
	- There are as many ways of removing k elements as there is leaving k elements

	3.6 In the recursive function S early in the section `recursion & recurrences`, assume that instead of returning
			S(seq, i+1) + seq[i], the function simply returned sec[0] + S(seq[1:]). What would the asymptotic running time be ?
			- S(seq, i+1) + seq[i] = T(n-1) + 1
			- seq[0] + S(seq[1:]) = T(1) + n-1
			- T(1) + n-1
			- T(n) + n.(n-1)
			= 0(n2)
	
	3.7 Solve the following recurrences using repeated substitution ?
			T(n) = T(n-1) + n 

			={n-1-1+n-1}+n
			={n-1-1-1+n-1-1+n}+n
			T(1)=(n-i)+n-i+n.i		#let i=n
			= 0(n2)

			T(n) = 2T(n-1) + 1 
			n(1) = 2n-2+1
			n(1) = 2n-1
			
			n(2) = 2{2(n-1-1)+1}+1
			n(2) = 2{2(n-2)+1}+1
			= 2{2n-4+1}+1
			= 2{2n-3}+1
			= 4n-5

			 n(3) = 2{2{2(n-1-1-1)+1}+1}+1
			 n(3) = 2{2{2(n-3)+1}+1}+1
			 = 2{2{2n-6+1}+1}+1
			 = 2{2{2n-5}+1}+1
			 = 2{4n-10+1}+1
			 = 2{4n-9}+1
			 = 8n-17


			T(n) = 2T(n-1) + n
	
	3.8 Show that x^log y = y^log x, no matter the base of log ?

	3.9 Show that f(n) is 0(n) for the implementation of merge sort ?

	3.10 In merge sort objects are popped from the end of each half of the sequence(with pop()).
			 It might be more intuitive to pop from the beginning with pop(0), to avoid reversing res.
			 But pop(0), like insert(0), is a linear operation, as opposed to pop(), which is constant.
			 What does this switch mean to the overall running time?
