- working with sums
- python
- sigma sum ([)
- exponent ^
- logarithm(base, n)

sum( a * y for y in n) in math not a [ y =

	n
	[ay 
	i=m
/
	[f(i) equivalent sum(f(i) for i in range(m,n+1))

multiplicative constants:

c(f(m)+..+f(n)) = cf(m)+..+cf(n)
n       n       n
[f(i) + [g(i) = [ f(i) + g(i)
i=m     i=m     i=m 

tournaments:
i). round-robin/ handshake problem
- the soln: n-1+n-2..+0 = sum(i for i in range(n))
n-1
[i = n(n-1)/2
i=0

 							49
caveat: sum of 100 numbers with 50 pairings gives us 101[i
							i=0

ii). hare & the tortoise/ knockout system
h-1
[2^i = n-1
i=0
	n=2^h gives hare
	h=log n gives tortoise

permutations as orderings of n objects. n!
n . (n-1) . (n-2) . .. . 1

caveat: 2^a+b is 2^a * 2^b

binomial co-efficient/combinations as a combinations of k elements drawn from set n

C(n,k)

popular algo sol:

0). T(n)=T(n-1)+1 - processing sequence 0(n)
1). T(n)=T(n-1)+n - handshake problem 0(n^2)
2). T(n)=2T(n-1)+1 - towers of hanoi 0(2n)
3). T(n)=2T(n-1)+n  
4). T(n)=T(n/2)+1 - binary search 0(lg n)
5). T(n)=T(n/2)+n - randomized select 0(n)
6). T(n)=2T(n/2)+1 - tree traversal 0(n)
7). T(n)=2T(n/2)+n - sorting by divide & conquer 0(nlg n)

3).
	use n = 2T(n-1) + n
	2{2(n-1-1) + n-1} + n
	2{2{2(n-1-1-1) + n-1-1} +  n-1} + n
	2{2{2(n-3) + n-2} + n-1} + n
	= 2 . n + n
	= 2n
	= 0(2n)
4. 
	use n = n/2 + 1
	(n/2 + 1)
	{(n/4 + 1) + 1}
	{{(n/8 + 1) + 1} + 1}
using i = lg n as base case
									lg n-1
T(1) = T(n/2^i) + [1
									0
		 = 1	+ i
		 = 0(lg n) 

5.
	use n = n/2 + n
	(n/2 + n)
	{(n/4 + n/2) + n}
	{{(n/8 + n/4) + n/2} + n}
	{{{(n/16 + n/8) + n/4} + n/2} + n}
using i = lg n as base case
									lg n-1
T(1) = T(n/2^i) + [n/2
									0
			= T(1) + [(n/2^i)
			= 1 + n
			= 0(n)

6.
	use n as 2T(n/2) + 1
	2(n/2) + 1
	2{2(n/4) + 1} + 1
	2{2{2(n/8) + 1} + 1 + 1
	8(n/8) + 3
	n + lg n
	= 0(n)

7.
	// Needs more proof especially the root
	use n as 2T(n/2) + n
	2(n/2) + n
	2{2(n/4) + n/2} + n
	2{2{2(n/8) + n/4} + n/2} + n
	8{(n/8) + n.i/2^i + n
	n + n.lg n
	= 0(n lg n)

	1.1 Consider the statement `As machines get faster and memory cheaper, algorithms become less important`. Is this true or false? And Why?
			ans: As machines get faster and use more memory, poor algorithms will lead to disaster in performance.
	1.2 Find a way of checking whether two strings are anagrams of each other: `debit card & bad credit`?
			ans: By sorting the characters in the strings and counting each character's frequency using Collections.Counter would scale even better.
	
	2.1 Why would it be problematic to construct a multi-dimensional array with the expression [[0]*10]*10?
	-	It would be equivalent to using the same list 10 times.

	2.2 Assuming abit unrealistically that allocating a block of memory takes constant time provided you leave it uninitialized.
	You want an array of n integers, and you want to keep track of whether each entry is uninitialized or whether it contains a number you put there.
	This is a check you want to be able to do at constant time for any entry. How would you do this with only constant time for initialization?
	And how could you use this to initialize an empty adjacency array in constant time, thereby avoiding an otherwise obligatory quadratic min running time?
	-	A, B, C = size n
	- count of entries
	A[i] = x
	B[i] = count
	C[count] = i

	2.3 Show that 0 and  @ are inverses of each other;i.e. if f is 0(g), then g is @(f) & vice-versa?
	- f(n) >= cg(n) >= f(n)
	- g(n) are satisfied using constant 1/c

	2.4 Log can have different bases but this is not a big deal.
	To see why, consider the equation: log (b,n) = log(a,n)/log(a,b)
	set log(a,n)/log(a,b) as m
	b^m = n
	m log b = log n
	this neutralizes to a common base and m to a contant

	2.5 Show that any increasing exponential (0(k^n) for k>1)
	asymptotically dominates any polynomial (0(n^j) for j>0)
	-	k^n >= cn^j
	- set c = 1
	- k^n > n^j
	- n log(k,k) > j * log(k,n)
	- n > jlog(k,n)

	2.6 Show that any polynomial asymptotically dominates any 0(log(n)).
	- n^j > log n
	- j log n > log (log n)
	- set log n as m
	- jm > log m

	2.7 Asymptotic complexities of various operations on Python lists, such as;
	indexing, item assign, reversing, appending & inserting?
	How would these be in a linked list?
	- accessing a linked list involves traversing the list or atleast halfway giving linear running time
	- Swapping elements around is constant time
	- Modifying (inserting or deleting) is done in constant time for linked list.
	What about example list.extend?
	- Anything that involves finding or modifying a certain position basically takes constant time because the underlying implementation is arrays.
	- Swapping elements around is constant time
	- Modifying the list structure (by inserting or deleting element, except at the end) is generally linear
	2.8 Show that 0(f) + 0(g) = 0(f+g) ? Also try your hand with max(0(f), 0(g))=0(max(f,g)) = 0(f+g)
	- if function F(n) <= c.f(n)
	- G(n) <= c.g(n)
	- G(n) + F(n) <= c.g(n) + c.f(n)
	- c.(G(n) + F(n))

	- max(0(f),0(g)) = 0(max(f,g))
	- max(f,g) = 0(f+g)						# maximum value grows as fast as the sum

	2.9 Let T be an arbitrary rooted tree with atleast 3 nodes, where each node has exactly 2 children.
	If T has n leaves, how many nodes does it have?
	- number of leaves is n
	- number of node children is 2m
	- number of internal nodes is m
	= 2m = m + n-1			# internal nodes + except root
	= 0(n) = m + n-1
	= m <= n-1

	2.10 Show that acyclic DAG can have any underlying structure whatsoever. Any undirected graph can be the underlying graph for DAG,
	or, given a graph, you can always orient its edges so that the resulting digraph is a DAG
	- Numbering the edges. Orient the ordering from lower to higher numbers.

	2.12 Consider a graph representation. You use a dict and let each key be a pair(tuple) of two nodes, with corresponding value set to the edge weight.
	W[u, v] = 24. What are pros & cons of this approach? How would you mitigate the cons?
	- pros: You dont need to access all neighbours of a node
	- cons: Handling membership, finding the degree of a node is handled differently,
	potentially increasing complexity

	3.1 Show that the properties described in the section `Working with sums` are correct ?
	- c.f(n) + c.g(n)
	- c [ 0(f(n) + 0(g))
	- c [ 0(f(n) + g(n))

	3.2 Use rules of the road to show that n(n - 1)/2 is 0(n^2)
	- n^2/2 - n/2
	- n^2.k - n.k			# k constant factor
	- k(n^2 - n)
	- n^2 dominates the equation
	
	3.3 The sum of the first k non-negative integer powers of 2 is 2^k+1 - 1. Show how this property lets you represent any positive integer as binary number?
	- why binary works is because any sum of 2 to power k is equivalent to n-1 (i.e. n is next power of 2).
			k
	- [ 2^i = n - 1			# k+1 in this case is the tortoise i.e. height of soln
			k=0
	- n = 2^k+1 - 1
	- n = 2^(k+1)+1 - 1			# k = k + 1
	- n + (2^(k+1)) = 2^(k+1)+1 - 1
	- n + 2^(2) = 2^3 - 1		# using k = 1
	- n + 4 = 7
	- n = 3									# as powers of 2
	- n = 7									# as powers of 2

	3.4 In `hare & tortoise`, two methods of looking for a number are sketched. Turn these methods into number guessing algorithms & represent them as python programs?
	-	h = lg n
		T(n) = lg n
		= lg (lg n)
		having lg n as m
		= lg m
	- 2^h = n

	3.5 Show that C(n,k) = C(n,n-k) ?
	- C(n, k) = n!/k!(n-k)!
	- C(n, n-k) = n!/(n-k)!(n-(n-k))!
	- C(n, n-k) = n!/(n-k)!k!
	- There are as many ways of removing k elements as there is leaving k elements

	3.6 In the recursive function S early in the section `recursion & recurrences`, assume that instead of returning
			S(seq, i+1) + seq[i], the function simply returned sec[0] + S(seq[1:]). What would the asymptotic running time be ?
			- S(seq, i+1) + seq[i] = T(n-1) + 1
			- seq[0] + S(seq[1:]) = T(1) + n-1
			- T(1) + n-1
			- T(n) + n.(n-1)
			= 0(n2)
	
	3.7 Solve the following recurrences using repeated substitution ?
			T(n) = T(n-1) + n 

			={n-1-1+n-1}+n
			={n-1-1-1+n-1-1+n}+n
			T(1)=(n-i)+n-i+n.i		#let i=n
			= 0(n2)

			T(n) = 2T(n-1) + 1 
			n(1) = 2n-2+1
			n(1) = 2n-1
			
			n(2) = 2{2(n-1-1)+1}+1
			n(2) = 2{2(n-2)+1}+1
			= 2{2n-4+1}+1
			= 2{2n-3}+1
			= 4n-5

			 n(3) = 2{2{2(n-1-1-1)+1}+1}+1
			 n(3) = 2{2{2(n-3)+1}+1}+1
			 = 2{2{2n-6+1}+1}+1
			 = 2{2{2n-5}+1}+1
			 = 2{4n-10+1}+1
			 = 2{4n-9}+1
			 = 8n-17


			T(n) = 2T(n-1) + n
	
	3.8 Show that x^log y = y^log x, no matter the base of log ?

	3.9 Show that f(n) is 0(n) for the implementation of merge sort ?

	3.10 In merge sort objects are popped from the end of each half of the sequence(with pop()).
			 It might be more intuitive to pop from the beginning with pop(0), to avoid reversing res.
			 But pop(0), like insert(0), is a linear operation, as opposed to pop(), which is constant.
			 What does this switch mean to the overall running time?
