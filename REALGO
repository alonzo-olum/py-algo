- working with sums
- python
- sigma sum ([)
- exponent ^
- logarithm(base, n)

sum( a * y for y in n) in math not a [ y =

	n
	[ay 
	i=m
/
	[f(i) equivalent sum(f(i) for i in range(m,n+1))

multiplicative constants:

c(f(m)+..+f(n)) = cf(m)+..+cf(n)
n       n       n
[f(i) + [g(i) = [ f(i) + g(i)
i=m     i=m     i=m 

tournaments:
i). round-robin/ handshake problem
- the soln: n-1+n-2..+0 = sum(i for i in range(n))
n-1
[i = n(n-1)/2
i=0

 							49
caveat: sum of 100 numbers with 50 pairings gives us 101[i
							i=0

ii). hare & the tortoise/ knockout system
h-1
[2^i = n-1
i=0
	n=2^h gives hare
	h=log n gives tortoise

permutations as orderings of n objects. n!
n . (n-1) . (n-2) . .. . 1

caveat: 2^a+b is 2^a * 2^b

binomial co-efficient/combinations as a combinations of k elements drawn from set n

C(n,k)

popular algo sol:

0). T(n)=T(n-1)+1 - processing sequence 0(n)
1). T(n)=T(n-1)+n - handshake problem 0(n^2)
2). T(n)=2T(n-1)+1 - towers of hanoi 0(2n)
3). T(n)=2T(n-1)+n  
4). T(n)=T(n/2)+1 - binary search 0(lg n)
5). T(n)=T(n/2)+n - randomized select 0(n)
6). T(n)=2T(n/2)+1 - tree traversal 0(n)
7). T(n)=2T(n/2)+n - sorting by divide & conquer 0(nlg n)

3).
	use n = 2T(n-1) + n
	2{2(n-1-1) + n-1} + n
	2{2{2(n-1-1-1) + n-1-1} +  n-1} + n
	2{2{2(n-3) + n-2} + n-1} + n
	= 2 . n + n
	= 2n
	=0(2n)
4. 
	use n = n/2 + 1
	(n/2 + 1)
	{(n/4 + 1) + 1}
	{{(n/8 + 1) + 1} + 1}
using i = lg n as base case
									lg n-1
T(1) = T(n/2^i) + [1
									0
		 = 1	+ i
		 = 0(lg n) 

5.
	use n = n/2 + n
	(n/2 + n)
	{(n/4 + n/2) + n}
	{{(n/8 + n/4) + n/2} + n}
	{{{(n/16 + n/8) + n/4} + n/2} + n}
using i = lg n as base case
									lg n-1
T(1) = T(n/2^i) + [n/2
									0
			= T(1) + [(n/2^i)
			= 1 + n
			= 0(n)

6.
	use n as 2T(n/2) + 1
	2(n/2) + 1
	2{2(n/4) + 1} + 1
	2{2{2(n/8) + 1} + 1 + 1
	8(n/8) + 3
	n + lg n
	= 0(n)

7.
	// Needs more proof especially the root
	use n as 2T(n/2) + n
	2(n/2) + n
	2{2(n/4) + n/2} + n
	2{2{2(n/8) + n/4} + n/2} + n
	8{(n/8) + n.i/2^i + n
	n + n.lg n
	= 0(n lg n)

	1.1 Consider the statement `As machines get faster and memory cheaper, algorithms become less important`. Is this true or false? And Why?
			ans: As machines get faster and use more memory, poor algorithms will lead to disaster in performance.
	1.2 Find a way of checking whether two strings are anagrams of each other: `debit card & bad credit`?
			ans: By sorting the characters in the strings and counting each character's frequency using Collections.Counter would scale even better.
	
	2.1 Why would it be problematic to construct a multi-dimensional array with the expression [[0]*10]*10?
	-	It would be equivalent to using the same list 10 times.

	2.2 Assuming abit unrealistically that allocating a block of memory takes constant time provided you leave it uninitialized.
	You want an array of n integers, and you want to keep track of whether each entry is uninitialized or whether it contains a number you put there.
	This is a check you want to be able to do at constant time for any entry. How would you do this with only constant time for initialization?
	And how could you use this to initialize an empty adjacency array in constant time, thereby avoiding an otherwise obligatory quadratic min running time?
	-	A, B, C = size n
	- count of entries
	A[i] = x
	B[i] = count
	C[count] = i

	2.3 Show that 0 and  @ are inverses of each other;i.e. if f is 0(g), then g is @(f) & vice-versa?
	- f(n) >= cg(n) >= f(n)
	- g(n) are satisfied using constant 1/c

	2.4 Log can have different bases but this is not a big deal.
	To see why, consider the equation: log (b,n) = log(a,n)/log(a,b)
	set log(a,n)/log(a,b) as m
	b^m = n
	m log b = log n
	this neutralizes the base to constant decimal (10) and m to a contant

	2.5 Show that any increasing exponential (0(k^n) for k>1)
	asymptotically dominates any polynomial (0(n^j) for j>0)
	-	k^n >= cn^j
	- set c = 1
	- k^n > n^j
	- n log(k,k) > log(k,n)
	- n > jlog(k,n)

	2.6 Show that any polynomial asymptotically dominates any 0(log(n)).
	- n^j > log n
	- j log n > log (log n)
	- set log n as m
	- jm > log m

	2.7 Asymptotic complexities of various operations on Python lists, such as;
	indexing, item assign, reversing, appending & inserting?
	How would these be in a linked list?
	What about example list.extend?
	- anything that involves finding or modifying a certain position basically takes constant time because the underlying implementation is arrays.
	- accessing a linked list involves traversing the list or atleast halfway giving linear running time
	- Swapping elements around in both is constant time
	- Modifying the list structure (by inserting or deleting element, except at the end) is generally linear for arrays/lists but can be done in constant time for linked list.

	2.8 Show that 0(f) + 0(g) = 0(f+g) ? Also try your hand with max(0(f), 0(g))=0(max(f,g)) = 0(f+g)
	- if function F(n) <= c.f(n)
	- G(n) <= c.g(n)
	- G(n) + F(n) <= c.g(n) + c.f(n)
	- c.(G(n) + F(n))

	- max(0(f),0(g)) = 0(max(f,g))
	- max(f,g) = 0(f+g)						# maximum value grows as fast as the sum

	2.9 Let T be an arbitrary rooted tree with atleast 3 nodes, where each node has exactly 2 children.
	If T has n leaves, how many nodes does it have?
	- number of leaves as n
	- number of each node children as 2m
	- m + n-1
	- m = n-1

	2.10 Show that acyclic DAG can have any underlying structure whatsoever. Any undirected graph can be the underlying graph for DAG,
	or, given a graph, you can always orient its edges so that the resulting digraph is a DAG
	- Numbering the edges. Orient the ordering from lower to higher numbers.

	2.12 Consider a graph representation. You use a dict and let each key be a pair(tuple) of two nodes, with corresponding value set to the edge weight.
	W[u, v] = 24. What are pros & cons of this approach? How would you mitigate the cons?
	- You dont need to access all neighbours of a node
